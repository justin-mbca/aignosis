import gradio as gr
from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer
import openai
import docx
import os
from dotenv import load_dotenv
from process_file import extract_key_value_pairs
import json

# Load environment variables from .env file
load_dotenv()

# Define label mapping
LABEL_MAPPING = {
    "LABEL_0": {
        "ä¸­æ–‡": "ä½Žé£Žé™©",
        "English": "Low Risk"
    },
    "LABEL_1": {
        "ä¸­æ–‡": "ä¸­é£Žé™©",
        "English": "Moderate Risk"
    },
    "LABEL_2": {
        "ä¸­æ–‡": "é«˜é£Žé™©",
        "English": "High Risk"
    }
}

# Define the models
MODELS = {
    "BioBERT": "dmis-lab/biobert-base-cased-v1.1",
    "PubMedBERT": "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract",
    "ClinicalBERT": "emilyalsentzer/Bio_ClinicalBERT"
}

# Load pipelines for each model
pipelines = {}
tokenizers = {}
for model_name, model_path in MODELS.items():
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=3)
    pipelines[model_name] = pipeline("text-classification", model=model, tokenizer=tokenizer)
    tokenizers[model_name] = tokenizer


def split_text(text, tokenizer, max_length=512):
    tokens = tokenizer.tokenize(text)
    chunks = []
    for i in range(0, len(tokens), max_length):
        chunk_tokens = tokens[i:i+max_length]
        chunk_text = tokenizer.convert_tokens_to_string(chunk_tokens)
        chunks.append(chunk_text)
    return chunks

# Classify text using chunks to handle long inputs


def classify_with_chunks(model_name, text):
    classifier = pipelines[model_name]
    tokenizer = tokenizers[model_name]
    chunks = split_text(text, tokenizer)
    all_predictions = []
    for chunk in chunks:
        # ToDO: Remove truncation
        preds = classifier(chunk, truncation=True, max_length=512)
        all_predictions.extend(preds)
    return all_predictions

# Define cardiovascular disease classification logic


def classify_cardiovascular_disease(symptoms, history, lab_params, lang="ä¸­æ–‡"):
    diseases = []
    recommendations = []

    if lang == "English":
        # Hypertension
        if lab_params.get("Systolic BP (mmHg)", 0) > 180 or lab_params.get("Diastolic BP (mmHg)", 0) > 120:
            diseases.append("Hypertension (Severe)")
            recommendations.append(
                "This is an emergency. Please seek medical attention immediately.")
        elif lab_params.get("Systolic BP (mmHg)", 0) > 160 or lab_params.get("Diastolic BP (mmHg)", 0) > 100:
            diseases.append("Hypertension (Moderate)")
            recommendations.append(
                "Monitor your blood pressure, reduce salt intake, maintain a healthy diet, and consult your doctor.")
        elif lab_params.get("Systolic BP (mmHg)", 0) > 140 or lab_params.get("Diastolic BP (mmHg)", 0) > 90:
            diseases.append("Hypertension (Mild)")
            recommendations.append(
                "Regularly monitor your blood pressure and maintain a healthy lifestyle.")

        # Coronary Artery Disease (CAD)
        if history.get("Family history of heart disease?", "No") == "Yes" or lab_params.get("LDL-C (mg/dL)", 0) > 130:
            diseases.append("Coronary Artery Disease")
            recommendations.append(
                "Consider a cardiac health check, avoid high-fat diets, and maintain regular exercise.")

        # Myocardial Infarction (MI)
        if symptoms.get("Chest pain triggered by exertion?", "No") == "Yes" and lab_params.get("Troponin I/T (ng/mL)", 0) > 0.04:
            diseases.append("Myocardial Infarction")
            recommendations.append(
                "This is an emergency. Please seek medical attention immediately.")

        # Hyperlipidemia
        if lab_params.get("Total Cholesterol (mg/dL)", 0) > 200 or lab_params.get("LDL-C (mg/dL)", 0) > 130:
            diseases.append("Hyperlipidemia")
            recommendations.append(
                "Reduce high-fat foods, increase fiber-rich foods, and consult your doctor.")

        # Heart Failure
        if symptoms.get("Shortness of breath?", "No") == "Yes" and lab_params.get("Troponin I/T (ng/mL)", 0) > 0.1:
            diseases.append("Heart Failure")
            recommendations.append(
                "This is an emergency. Please seek medical attention immediately.")

        if not diseases:
            diseases.append(
                "No significant cardiovascular disease risk detected")
            recommendations.append(
                "Maintain a healthy lifestyle and have regular health check-ups.")

    else:
        # Hypertension
        if lab_params.get("æ”¶ç¼©åŽ‹ (mmHg)", 0) > 180 or lab_params.get("èˆ’å¼ åŽ‹ (mmHg)", 0) > 120:
            diseases.append("é«˜è¡€åŽ‹ (ä¸¥é‡)")
            recommendations.append("è¿™æ˜¯ç´§æ€¥æƒ…å†µï¼Œè¯·ç«‹å³å°±åŒ»ã€‚")
        elif lab_params.get("æ”¶ç¼©åŽ‹ (mmHg)", 0) > 160 or lab_params.get("èˆ’å¼ åŽ‹ (mmHg)", 0) > 100:
            diseases.append("é«˜è¡€åŽ‹ (ä¸­åº¦)")
            recommendations.append("å»ºè®®ç›‘æµ‹è¡€åŽ‹ï¼Œå‡å°‘ç›åˆ†æ‘„å…¥ï¼Œä¿æŒå¥åº·é¥®é£Ÿï¼Œå¹¶å’¨è¯¢åŒ»ç”Ÿã€‚")
        elif lab_params.get("æ”¶ç¼©åŽ‹ (mmHg)", 0) > 140 or lab_params.get("èˆ’å¼ åŽ‹ (mmHg)", 0) > 90:
            diseases.append("é«˜è¡€åŽ‹ (è½»åº¦)")
            recommendations.append("å»ºè®®å®šæœŸç›‘æµ‹è¡€åŽ‹ï¼Œä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼ã€‚")

        # Coronary Artery Disease (CAD)
        if history.get("æ˜¯å¦æœ‰å¿ƒè„ç—…å®¶æ—å²ï¼Ÿ", "å¦") == "æ˜¯" or lab_params.get("ä½Žå¯†åº¦è„‚è›‹ç™½ (LDL-C, mg/dL)", 0) > 130:
            diseases.append("å† å¿ƒç—…")
            recommendations.append("å»ºè®®è¿›è¡Œå¿ƒè„å¥åº·æ£€æŸ¥ï¼Œé¿å…é«˜è„‚é¥®é£Ÿï¼Œå¹¶ä¿æŒé€‚åº¦è¿åŠ¨ã€‚")

        # Myocardial Infarction (MI)
        if symptoms.get("èƒ¸ç—›æ˜¯å¦åœ¨åŠ³ç´¯æ—¶åŠ é‡ï¼Ÿ", "å¦") == "æ˜¯" and lab_params.get("è‚Œé’™è›‹ç™½ (Troponin I/T, ng/mL)", 0) > 0.04:
            diseases.append("å¿ƒè‚Œæ¢—å¡ž")
            recommendations.append("è¿™æ˜¯ç´§æ€¥æƒ…å†µï¼Œè¯·ç«‹å³å°±åŒ»ã€‚")

        # Hyperlipidemia
        if lab_params.get("æ€»èƒ†å›ºé†‡ (Total Cholesterol, mg/dL)", 0) > 200 or lab_params.get("ä½Žå¯†åº¦è„‚è›‹ç™½ (LDL-C, mg/dL)", 0) > 130:
            diseases.append("é«˜è„‚è¡€ç—‡")
            recommendations.append("å»ºè®®å‡å°‘é«˜è„‚é¥®é£Ÿï¼Œå¢žåŠ å¯Œå«çº¤ç»´çš„é£Ÿç‰©ï¼Œå¹¶å’¨è¯¢åŒ»ç”Ÿã€‚")

        # Heart Failure
        if symptoms.get("æ˜¯å¦å‘¼å¸å›°éš¾ï¼Ÿ", "å¦") == "æ˜¯" and lab_params.get("è‚Œé’™è›‹ç™½ (Troponin I/T, ng/mL)", 0) > 0.1:
            diseases.append("å¿ƒåŠ›è¡°ç«­")
            recommendations.append("è¿™æ˜¯ç´§æ€¥æƒ…å†µï¼Œè¯·ç«‹å³å°±åŒ»ã€‚")

        if not diseases:
            diseases.append("æ— æ˜Žæ˜¾å¿ƒè¡€ç®¡ç–¾ç—…é£Žé™©")
            recommendations.append("ä¿æŒå¥åº·çš„ç”Ÿæ´»æ–¹å¼ï¼Œå®šæœŸè¿›è¡Œå¥åº·æ£€æŸ¥ã€‚")

    return diseases, recommendations

MODEL_EXPLANATIONS = {
    "BioBERT": {
        "ä¸­æ–‡": "BioBERT æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹ç”Ÿç‰©åŒ»å­¦æ–‡æœ¬è®­ç»ƒçš„æ¨¡åž‹ï¼Œé€‚ç”¨äºŽåˆ†æžåŒ»å­¦ç›¸å…³çš„æ–‡æœ¬ã€‚",
        "English": "BioBERT is a model pre-trained on biomedical text, suitable for analyzing medical-related content."
    },
    "PubMedBERT": {
        "ä¸­æ–‡": "PubMedBERT æ˜¯åŸºäºŽ PubMed æ•°æ®è®­ç»ƒçš„æ¨¡åž‹ï¼Œä¸“æ³¨äºŽç”Ÿç‰©åŒ»å­¦æ–‡çŒ®çš„ç†è§£ã€‚",
        "English": "PubMedBERT is trained on PubMed data and focuses on understanding biomedical literature."
    },
    "ClinicalBERT": {
        "ä¸­æ–‡": "ClinicalBERT æ˜¯é’ˆå¯¹ä¸´åºŠæ–‡æœ¬ï¼ˆå¦‚ç”µå­ç—…åŽ†ï¼‰ä¼˜åŒ–çš„æ¨¡åž‹ï¼Œé€‚åˆåˆ†æžæ‚£è€…ç›¸å…³çš„ä¸´åºŠæ•°æ®ã€‚",
        "English": "ClinicalBERT is optimized for clinical text (such as electronic medical records) and is suitable for analyzing patient-related clinical data."
    }
}


def aggregate_model_predictions(results, lang="ä¸­æ–‡"):
    """
    Aggregates probabilities from all models to determine the overall risk level,
    and outputs labels in the specified language.
    """
    # Define risk labels based on language
    if lang == "English":
        risk_labels = ["Low Risk", "Moderate Risk", "High Risk"]
    else:
        risk_labels = ["ä½Žé£Žé™©", "ä¸­é£Žé™©", "é«˜é£Žé™©"]

    # Initialize aggregated probabilities
    aggregated_probabilities = {label: 0 for label in risk_labels}
    model_count = 0

    for model_result in results:
        if isinstance(model_result, dict) and "probabilities" in model_result:
            for risk, score in model_result["probabilities"].items():
                # Only aggregate if the risk label matches the current language
                if risk in aggregated_probabilities:
                    aggregated_probabilities[risk] += score
            model_count += 1

    # Avoid division by zero
    if model_count == 0:
        return None, aggregated_probabilities

    # Average the probabilities
    for risk in aggregated_probabilities:
        aggregated_probabilities[risk] /= model_count

    # Determine the most likely risk level
    most_likely = max(aggregated_probabilities, key=aggregated_probabilities.get)
    return most_likely, aggregated_probabilities


def analyze_structured_inputs(symptoms, history, lab_params, file_output, lang):

    # Replace None values in symptoms with "å¦"/"No"
    if lang == "ä¸­æ–‡":
        symptoms = {key: (value if value is not None else "å¦")
                    for key, value in symptoms.items()}
        section_user = "### ðŸ“ ç”¨æˆ·è¾“å…¥"
        section_symptoms = "#### ðŸ©º ç—‡çŠ¶"
        section_history = "#### ðŸ¥ ç—…å²"
        section_lab = "#### ðŸ§ª å®žéªŒå®¤å‚æ•°"
        section_disease = "### ðŸ©º ç–¾ç—…åˆ†ç±»"
        section_recommend = "### ðŸ’¡ å»ºè®®"
        section_model = "### æ¨¡åž‹é¢„æµ‹"
        section_agg = "### ç»¼åˆåˆ†æž"
        bullet = "ðŸ”¹"
        risk_label = "é£Žé™©ç­‰çº§"
        prob_label = "æ¦‚çŽ‡åˆ†å¸ƒ"
        explain_label = "æ¨¡åž‹è§£é‡Š"
        agg_risk = "ç»¼åˆé£Žé™©ç­‰çº§"
        agg_prob = "ç»¼åˆæ¦‚çŽ‡åˆ†å¸ƒ"
        agg_explain = "æ¨¡åž‹é¢„æµ‹å¯èƒ½å­˜åœ¨å·®å¼‚ï¼Œå› ä¸ºå®ƒä»¬åŸºäºŽä¸åŒçš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚å»ºè®®æ ¹æ®ç»¼åˆåˆ†æžç»“æžœé‡‡å–è¡ŒåŠ¨ï¼Œå¹¶åœ¨å¿…è¦æ—¶å’¨è¯¢åŒ»ç”Ÿã€‚"
        history = {k: (v if v is not None else "å¦")
                   for k, v in history.items()}
    else:
        symptoms = {key: (value if value is not None else "No")
                    for key, value in symptoms.items()}
        section_user = "### ðŸ“ User Inputs"
        section_symptoms = "#### ðŸ©º Symptoms"
        section_history = "#### ðŸ¥ Medical History"
        section_lab = "#### ðŸ§ª Lab Parameters"
        section_disease = "### ðŸ©º Disease Classification"
        section_recommend = "### ðŸ’¡ Recommendations"
        section_model = "### Model Predictions"
        section_agg = "### Aggregated Analysis"
        bullet = "ðŸ”¹"
        risk_label = "Risk Level"
        prob_label = "Probability Distribution"
        explain_label = "Model Explanation"
        agg_risk = "Overall Risk Level"
        agg_prob = "Aggregated Probability Distribution"
        agg_explain = "Model predictions may differ because they are trained on different datasets. Please act according to the combined analysis and consult a doctor if necessary."

    # Combine structured inputs into a single text representation
    structured_text = (
        f"{section_user}:\n\n"
        f"{section_symptoms}:\n" +
        "\n".join([f"{bullet} {q}: {a}" for q, a in symptoms.items()]) +
        f"\n\n{section_history}:\n" +
        "\n".join([f"{bullet} {q}: {a}" for q, a in history.items()]) +
        f"\n\n{section_lab}:\n" +
        "\n".join([f"{bullet} {q}: {a}" for q, a in lab_params.items()])
    )

    # Process file if provided
    if file_output:
        file_data = process_file(file_output, lang)
        if isinstance(file_data, str):
            try:
                file_data = json.loads(file_data)
            except json.JSONDecodeError:
                return f"Error processing file: {file_data}"
    if file_data:
        if lang == "ä¸­æ–‡":
            file_section = "### ä¸Šä¼ æ–‡ä»¶å†…å®¹è§£æž"
        else:
            file_section = "### File Content Analysis"
        if isinstance(file_data, dict):
            file_content = "\n".join([
                f"{bullet} {k}: {v}" for k, v in file_data.items()
            ])
        else:
            file_content = str(file_data)
        structured_text += f"\n\n{file_section}:\n{file_content}"


    # Classify cardiovascular diseases and get recommendations
    diseases, recommendations = classify_cardiovascular_disease(
        symptoms, history, lab_params, lang)

    # Get predictions from all models
    model_results = []
    for model_name in pipelines:
        try:
            predictions = classify_with_chunks(model_name, structured_text)
            print(predictions)
            probabilities = {
                LABEL_MAPPING[pred["label"]][lang]: pred["score"] for pred in predictions}
            most_likely = max(probabilities, key=probabilities.get)
            explanation = MODEL_EXPLANATIONS[model_name][lang]
            model_results.append({
                "model_name": model_name,
                "most_likely": most_likely,
                "probabilities": probabilities,
                "explanation": explanation
            })
        except Exception as e:
            model_results.append({
                "model_name": model_name,
                "error": str(e)
            })

    # Aggregate predictions
    aggregated_risk, aggregated_probabilities = aggregate_model_predictions(
        model_results, lang)

    # Format the results for display
    formatted_results = [structured_text]
    formatted_results.append(
        f"{section_disease}:\n" +
        "\n".join([f"{bullet} {disease}" for disease in diseases])
    )
    formatted_results.append(
        f"{section_recommend}:\n" +
        "\n".join(
            [f"{bullet} {recommendation}" for recommendation in recommendations])
    )

    # Add model-specific results
    formatted_results.append(f"{section_model}:")
    for result in model_results:
        if "error" in result:
            formatted_results.append(f"- **{result['model_name']}**: Error: {result['error']}")
        else:
            formatted_results.append(
                f"- **{result['model_name']}**:\n"
                f"  **{risk_label}:** {result['most_likely']}\n"
                f"  **{prob_label}:**\n" +
                "\n".join([f"    {bullet} {risk}: {score:.2f}" for risk, score in result["probabilities"].items()]) +
                f"\n  **{explain_label}:** {result['explanation']}\n"
            )

    # Add aggregated analysis
    formatted_results.append(
        f"{section_agg}:\n"
        f"- **{agg_risk}:** {aggregated_risk}\n"
        f"- **{agg_prob}:**\n" +
        "\n".join([f"  {bullet} {risk}: {score:.2f}" for risk, score in aggregated_probabilities.items()]) +
        f"\n- **{('è¯´æ˜Ž' if lang == 'ä¸­æ–‡' else 'Explanation')}:** {agg_explain}"
    )

    return "\n\n".join(formatted_results)

# Create Gradio interface for each language
def make_tab(lang):
    """
    Creates a tab for the specified language (Chinese or English).
    """
    L = {
        "yes": "æ˜¯" if lang == "ä¸­æ–‡" else "Yes",
        "no": "å¦" if lang == "ä¸­æ–‡" else "No",
        "nums": [
            ("æ”¶ç¼©åŽ‹ (mmHg)" if lang == "ä¸­æ–‡" else "Systolic BP (mmHg)", 60, 220, 120),
            ("èˆ’å¼ åŽ‹ (mmHg)" if lang == "ä¸­æ–‡" else "Diastolic BP (mmHg)", 40, 120, 80),
            ("ä½Žå¯†åº¦è„‚è›‹ç™½ (LDL-C, mg/dL)" if lang == "ä¸­æ–‡" else "LDL-C (mg/dL)", 50, 200, 100),
            ("é«˜å¯†åº¦è„‚è›‹ç™½ (HDL-C, mg/dL)" if lang == "ä¸­æ–‡" else "HDL-C (mg/dL)", 20, 100, 50),
            ("æ€»èƒ†å›ºé†‡ (Total Cholesterol, mg/dL)" if lang == "ä¸­æ–‡" else "Total Cholesterol (mg/dL)", 100, 300, 200),
            ("è‚Œé’™è›‹ç™½ (Troponin I/T, ng/mL)" if lang == "ä¸­æ–‡" else "Troponin I/T (ng/mL)", 0, 50, 0.01)
        ]
    }
    yesno = [L["yes"], L["no"]]

    # Grouped questions
    symptom_questions = [
        "èƒ¸ç—›æ˜¯å¦åœ¨åŠ³ç´¯æ—¶åŠ é‡ï¼Ÿ" if lang == "ä¸­æ–‡" else "Is chest pain aggravated by exertion?",
        "æ˜¯å¦ä¸ºåŽ‹è¿«æ„Ÿæˆ–ç´§ç¼©æ„Ÿï¼Ÿ" if lang == "ä¸­æ–‡" else "Is it a pressing or tightening sensation?",
        "æ˜¯å¦æŒç»­è¶…è¿‡5åˆ†é’Ÿï¼Ÿ" if lang == "ä¸­æ–‡" else "Does it last more than 5 minutes?",
        "æ˜¯å¦æ”¾å°„è‡³è‚©/èƒŒ/ä¸‹å·´ï¼Ÿ" if lang == "ä¸­æ–‡" else "Does it radiate to shoulder/back/jaw?",
        "æ˜¯å¦åœ¨ä¼‘æ¯åŽç¼“è§£ï¼Ÿ" if lang == "ä¸­æ–‡" else "Is it relieved by rest?",
        "æ˜¯å¦ä¼´å†·æ±—ï¼Ÿ" if lang == "ä¸­æ–‡" else "Is it accompanied by cold sweat?",
        "æ˜¯å¦å‘¼å¸å›°éš¾ï¼Ÿ" if lang == "ä¸­æ–‡" else "Is there shortness of breath?",
        "æ˜¯å¦æ¶å¿ƒæˆ–å‘•åï¼Ÿ" if lang == "ä¸­æ–‡" else "Is there nausea or vomiting?",
        "æ˜¯å¦å¤´æ™•æˆ–æ™•åŽ¥ï¼Ÿ" if lang == "ä¸­æ–‡" else "Is there dizziness or fainting?",
        "æ˜¯å¦å¿ƒæ‚¸ï¼Ÿ" if lang == "ä¸­æ–‡" else "Is there palpitations?"
    ]
    history_questions = [
        "æ˜¯å¦æ‚£æœ‰é«˜è¡€åŽ‹ï¼Ÿ" if lang == "ä¸­æ–‡" else "Do you have hypertension?",
        "æ˜¯å¦æ‚£ç³–å°¿ç—…ï¼Ÿ" if lang == "ä¸­æ–‡" else "Do you have diabetes?",
        "æ˜¯å¦æœ‰é«˜è¡€è„‚ï¼Ÿ" if lang == "ä¸­æ–‡" else "Do you have hyperlipidemia?",
        "æ˜¯å¦å¸çƒŸï¼Ÿ" if lang == "ä¸­æ–‡" else "Do you smoke?",
        "æ˜¯å¦æœ‰å¿ƒè„ç—…å®¶æ—å²ï¼Ÿ" if lang == "ä¸­æ–‡" else "Family history of heart disease?",
        "è¿‘æœŸæ˜¯å¦æœ‰æƒ…ç»ªåŽ‹åŠ›ï¼Ÿ" if lang == "ä¸­æ–‡" else "Recent emotional stress?"
    ]

    # Create Gradio components
    with gr.Group():
        gr.Markdown("### ðŸ©º ç—‡çŠ¶ / Symptoms" if lang == "ä¸­æ–‡" else "### ðŸ©º Symptoms")
        symptom_fields = [gr.Radio(choices=yesno, label=q) for q in symptom_questions]

    with gr.Group():
        gr.Markdown("### ðŸ¥ ç—…å² / Medical History" if lang == "ä¸­æ–‡" else "### ðŸ¥ Medical History")
        history_fields = [gr.Radio(choices=yesno, label=q) for q in history_questions]

    with gr.Group():
        gr.Markdown("### ðŸ§ª å®žéªŒå®¤å‚æ•° / Lab Parameters" if lang == "ä¸­æ–‡" else "### ðŸ§ª Lab Parameters")
        lab_fields = [
            gr.Number(label=q, minimum=minv, maximum=maxv, value=val)
            for q, minv, maxv, val in L["nums"]
        ]

    with gr.Group():
        label = "ä¸Šä¼ æ–‡ä»¶" if lang == "ä¸­æ–‡" else "Upload File"
        gr.Markdown(label)
        file_input = gr.File(label=label, file_types=[
                             ".txt", ".pdf", ".docx"], elem_id="file_upload")

    # Combine all fields
    fields = symptom_fields + history_fields + lab_fields + [file_input]

    # Output and submit button
    output_text = gr.Textbox(label="ç»“æžœ / Results" if lang == "ä¸­æ–‡" else "Results")
    reset_button = gr.Button("é‡ç½®" if lang == "ä¸­æ–‡" else "Reset")
    submit_button = gr.Button("æäº¤ / Submit" if lang == "ä¸­æ–‡" else "Submit")

    # Submit button functionality
    submit_button.click(
        fn=lambda *inputs: analyze_structured_inputs(
            symptoms={q: inputs[i] for i, q in enumerate(symptom_questions)},
            history={q: inputs[i + len(symptom_questions)] for i, q in enumerate(history_questions)},
            lab_params={lab_fields[i].label: inputs[i + len(symptom_questions) + len(history_questions)] for i in range(len(lab_fields))},
            file_output=inputs[-1],
            lang=lang
        ),
        inputs=fields,
        outputs=[output_text]
    )

    reset_button.click(
        fn=lambda: [None] * len(fields),  # æ¸…ç©ºæ‰€æœ‰è¾“å…¥
        inputs=None,
        outputs=fields
    )

    # Create Gradio interface
    return gr.Column(fields + [submit_button, output_text, reset_button, gr.Markdown("---")])

def process_file(file, lang="English", mock=True):
    """
    Process the uploaded docx file and use OpenAI API to extract key-value pairs.
    If mock is True, return a fixed JSON structure for testing.
    """
    if mock:
        mock_data = {
            "ç™ŒèƒšæŠ—åŽŸ": {"Value": "3.22", "Unit": "ng/ml", "Reference Range": "â‰¤5"},
            "ç”²èƒŽè›‹ç™½": {"Value": "3.52", "Unit": "ng/ml", "Reference Range": "â‰¤7"},
            "å¿µç èŒ": {"Value": "æœªè§", "Unit": "åº¦"},
            "æ·‹çƒèŒ": {"Value": "æœªè§", "Unit": "åº¦"},
            "é«˜å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡": {"Value": "2.02", "Unit": "mmol", "Reference Range": ">1.04"},
            "ä½Žå¯†åº¦è„‚è›‹è‡¼èƒ†å›ºé†‡": {"Value": "4.43", "Unit": "mmol", "Reference Range": "<3.37"},
            "ç”˜æ²¹ä¸‰é†‹": {"Value": "1.25", "Unit": "mmol", "Reference Range": "<1.70"},
            "æ€»èƒ†å›ºé…ª": {"Value": "6.89", "Unit": "mmol", "Reference Range": "<5.18"},
            "å°¿ç´ ": {"Value": "6.27", "Unit": "mmol", "Reference Range": "3.10-8.80"},
            "æ€»äºŒæ°§åŒ–ç¢³": {"Value": "26.8", "Unit": "mmol", "Reference Range": "22.0-29.0"},
            "å°¿é…¸": {"Value": "236.0", "Unit": "Âµmol", "Reference Range": "155.0-357.0"},
            "è‚Œé…": {"Value": "63.0", "Unit": "Âµmol", "Reference Range": "41.0-81.0"}
        }
        return json.dumps(mock_data, indent=2, ensure_ascii=False)
    if file is None:
        return "No file uploaded."
    try:
        # Save uploaded file to a temp path
        temp_path = file.name
        result = extract_key_value_pairs(temp_path)
        if result is None:
            return "Could not extract key-value pairs. See logs for details."
        # Pretty print JSON result
        return json.dumps(result, indent=2, ensure_ascii=False)
    except Exception as e:
        return f"Error processing file: {e}"

# Launch Gradio app
if __name__ == "__main__":
    with gr.Blocks() as app:
        gr.Markdown("## ðŸŒ æ™ºèƒ½å¿ƒè¡€ç®¡è¯„ä¼°ç³»ç»Ÿ | Bilingual Cardiovascular Assistant")
        with gr.Tabs():
            with gr.TabItem("ä¸­æ–‡"):
                make_tab("ä¸­æ–‡")
            with gr.TabItem("English"):
                make_tab("English")
        app.launch(share=True)