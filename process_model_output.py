import openai
from dotenv import load_dotenv
import os

# Load environment variables from .env
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")


def summarize_model_outputs_llm(model_outputs, language="ä¸­æ–‡"):
    """
    Summarize model outputs using OpenAI GPT, returning the JSON summary string.
    Args:
        model_outputs: list of dicts with model results
        language: "ä¸­æ–‡" or "English"
    Returns:
        str: JSON summary from LLM
    """
    def format_model_outputs(outputs):
        formatted = ""
        for item in outputs:
            probs = "\n    ".join([f"ğŸ”¹ {k}: {v:.2f}" for k, v in item["probabilities"].items()])
            formatted += (
                f"- **{item['model_name']}**:\n"
                f"  **é£é™©ç­‰çº§:** {item['most_likely']}\n"
                f"  **æ¦‚ç‡åˆ†å¸ƒ:**\n"
                f"    {probs}\n"
                f"  **æ¨¡å‹è§£é‡Š:** {item['explanation']}\n\n"
            )
        return formatted

    formatted_text = format_model_outputs(model_outputs)

    if language == "ä¸­æ–‡":
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªåŒ»å­¦é£é™©åˆ†æåŠ©æ‰‹ã€‚

è¯·æ ¹æ®ä»¥ä¸‹ä¸‰ä¸ªç”Ÿç‰©åŒ»å­¦è¯­è¨€æ¨¡å‹ï¼ˆBioBERTã€PubMedBERTã€ClinicalBERTï¼‰å¯¹æŸæ–‡æœ¬çš„é£é™©é¢„æµ‹ï¼Œè¿›è¡Œæ€»ä½“åˆ†æä¸åˆ¤æ–­ã€‚

æ¯ä¸ªæ¨¡å‹æä¾›ï¼š
- é£é™©ç­‰çº§ï¼ˆé«˜é£é™©ã€ä¸­é£é™©ã€ä½é£é™©ï¼‰
- æ¦‚ç‡åˆ†å¸ƒ
- æ¨¡å‹çš„ç®€è¦è§£é‡Š

æ¨¡å‹è¾“å‡ºå¦‚ä¸‹ï¼š

{formatted_text}

ä»»åŠ¡ï¼š
1. æ€»ç»“ä¸‰ä¸ªæ¨¡å‹å¯¹è¯¥æ–‡æœ¬çš„æ•´ä½“é£é™©ç­‰çº§åˆ¤æ–­ã€‚
2. åˆ†ææ¨¡å‹ä¹‹é—´çš„ä¸€è‡´æ€§æˆ–å·®å¼‚ã€‚
3. ç»™å‡ºç³»ç»Ÿæ˜¯å¦åº”å°†è¯¥æ–‡æœ¬åˆ†ç±»ä¸ºâ€œé«˜é£é™©â€ã€â€œä¸­é£é™©â€æˆ–â€œä½é£é™©â€çš„å»ºè®®ã€‚
4. è¯·é¢å¤–æ·»åŠ  "å»ºè®®ç”¨æˆ·è¡ŒåŠ¨" å­—æ®µï¼Œä¸ºéä¸“ä¸šç”¨æˆ·æä¾›å»ºè®®ï¼Œè§£é‡Šæ˜¯å¦éœ€è¦çœ‹åŒ»ç”Ÿã€æ˜¯å¦ç´§æ€¥ã€æ˜¯å¦å¯ä»¥ç­‰å¾…è§‚å¯Ÿã€ä»¥åŠåº”å‡†å¤‡å“ªäº›ä¿¡æ¯ã€‚

å¦‚æœå¯èƒ½ï¼Œè¯·åœ¨è‹±æ–‡ç¿»è¯‘å‰åŠ ä¸Š"[English Translation]"ï¼Œä»¥ä¾¿å›½é™…å›¢é˜Ÿè¯†åˆ«ã€‚
"""
    else:
        prompt = f"""
You are a medical risk analysis assistant.

Given the risk assessment outputs from three different biomedical language models, analyze and summarize the overall risk based on their classifications and probability distributions.

Each model provides:
- a risk level (e.g., High Risk, Medium Risk, Low Risk)
- a probability for the assigned level
- a short explanation of the model's training background

Here are the model outputs:

{formatted_text}

Task:
1. Summarize the consensus risk level from the three models.
2. Explain any disagreement between models.
3. Suggest whether this case should be treated as "High Risk", "Medium Risk", or "Low Risk" in an automated system.
4. Please also add a "User Action Suggestion" field to provide non-expert users with advice on whether they need to see a doctor, if it's urgent, if they can wait and observe, and what information they should prepare.
"""
    client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3
    )
    return response.choices[0].message.content

if __name__ == "__main__":
    # Example usage for standalone test
    language = "ä¸­æ–‡"  # or "English"
    model_outputs = [
        {
            "model_name": "BioBERT",
            "most_likely": "é«˜é£é™©",
            "probabilities": {"é«˜é£é™©": 0.39756593108177185},
            "explanation": "BioBERT æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹ç”Ÿç‰©åŒ»å­¦æ–‡æœ¬è®­ç»ƒçš„æ¨¡å‹ï¼Œé€‚ç”¨äºåˆ†æåŒ»å­¦ç›¸å…³çš„æ–‡æœ¬ã€‚"
        },
        {
            "model_name": "PubMedBERT",
            "most_likely": "ä½é£é™©",
            "probabilities": {"ä½é£é™©": 0.5041127800941467},
            "explanation": "PubMedBERT æ˜¯åŸºäº PubMed æ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼Œä¸“æ³¨äºç”Ÿç‰©åŒ»å­¦æ–‡çŒ®çš„ç†è§£ã€‚"
        },
        {
            "model_name": "ClinicalBERT",
            "most_likely": "é«˜é£é™©",
            "probabilities": {"é«˜é£é™©": 0.4117318391799927},
            "explanation": "ClinicalBERT æ˜¯é’ˆå¯¹ä¸´åºŠæ–‡æœ¬ï¼ˆå¦‚ç”µå­ç—…å†ï¼‰ä¼˜åŒ–çš„æ¨¡å‹ï¼Œé€‚åˆåˆ†ææ‚£è€…ç›¸å…³çš„ä¸´åºŠæ•°æ®ã€‚"
        }
    ]
    print("=== Summary Result ===")
    summary = summarize_model_outputs_llm(model_outputs, language)
    print(summary)
