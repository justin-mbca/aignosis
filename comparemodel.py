import gradio as gr
from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer
import openai
import docx
import os
from dotenv import load_dotenv
from process_file import extract_key_value_pairs
from process_health_docx import extract_medical_data
from process_model_output import summarize_model_outputs_llm
import json
import re

# Load environment variables from .env file
load_dotenv()

# Define label mapping
LABEL_MAPPING = {
    "LABEL_0": {
        "ä¸­æ–‡": "ä½é£é™©",
        "English": "Low Risk"
    },
    "LABEL_1": {
        "ä¸­æ–‡": "ä¸­é£é™©",
        "English": "Moderate Risk"
    },
    "LABEL_2": {
        "ä¸­æ–‡": "é«˜é£é™©",
        "English": "High Risk"
    }
}

# Define the models
MODELS = {
    "BioBERT": "dmis-lab/biobert-base-cased-v1.1",
    "PubMedBERT": "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract",
    "ClinicalBERT": "emilyalsentzer/Bio_ClinicalBERT"
}

# Load pipelines for each model
pipelines = {}
for model_name, model_path in MODELS.items():
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=3)
    pipelines[model_name] = pipeline(
        "text-classification", model=model, tokenizer=tokenizer)

# Define cardiovascular disease classification logic


def classify_cardiovascular_disease(symptoms, history, lab_params, lang="ä¸­æ–‡"):
    diseases = []
    recommendations = []

    if lang == "English":
        # Hypertension
        if lab_params.get("Systolic BP (mmHg)", 0) > 180 or lab_params.get("Diastolic BP (mmHg)", 0) > 120:
            diseases.append("Hypertension (Severe)")
            recommendations.append(
                "This is an emergency. Please seek medical attention immediately.")
        elif lab_params.get("Systolic BP (mmHg)", 0) > 160 or lab_params.get("Diastolic BP (mmHg)", 0) > 100:
            diseases.append("Hypertension (Moderate)")
            recommendations.append(
                "Monitor your blood pressure, reduce salt intake, maintain a healthy diet, and consult your doctor.")
        elif lab_params.get("Systolic BP (mmHg)", 0) > 140 or lab_params.get("Diastolic BP (mmHg)", 0) > 90:
            diseases.append("Hypertension (Mild)")
            recommendations.append(
                "Regularly monitor your blood pressure and maintain a healthy lifestyle.")

        # Coronary Artery Disease (CAD)
        if history.get("Family history of heart disease?", "No") == "Yes" or lab_params.get("LDL-C (mg/dL)", 0) > 130:
            diseases.append("Coronary Artery Disease")
            recommendations.append(
                "Consider a cardiac health check, avoid high-fat diets, and maintain regular exercise.")

        # Myocardial Infarction (MI)
        if symptoms.get("Chest pain triggered by exertion?", "No") == "Yes" and lab_params.get("Troponin I/T (ng/mL)", 0) > 0.04:
            diseases.append("Myocardial Infarction")
            recommendations.append(
                "This is an emergency. Please seek medical attention immediately.")

        # Hyperlipidemia
        if lab_params.get("Total Cholesterol (mg/dL)", 0) > 200 or lab_params.get("LDL-C (mg/dL)", 0) > 130:
            diseases.append("Hyperlipidemia")
            recommendations.append(
                "Reduce high-fat foods, increase fiber-rich foods, and consult your doctor.")

        # Heart Failure
        if symptoms.get("Shortness of breath?", "No") == "Yes" and lab_params.get("Troponin I/T (ng/mL)", 0) > 0.1:
            diseases.append("Heart Failure")
            recommendations.append(
                "This is an emergency. Please seek medical attention immediately.")

        if not diseases:
            diseases.append(
                "No significant cardiovascular disease risk detected")
            recommendations.append(
                "Maintain a healthy lifestyle and have regular health check-ups.")

    else:
        # Hypertension
        if lab_params.get("æ”¶ç¼©å‹ (mmHg)", 0) > 180 or lab_params.get("èˆ’å¼ å‹ (mmHg)", 0) > 120:
            diseases.append("é«˜è¡€å‹ (ä¸¥é‡)")
            recommendations.append("è¿™æ˜¯ç´§æ€¥æƒ…å†µï¼Œè¯·ç«‹å³å°±åŒ»ã€‚")
        elif lab_params.get("æ”¶ç¼©å‹ (mmHg)", 0) > 160 or lab_params.get("èˆ’å¼ å‹ (mmHg)", 0) > 100:
            diseases.append("é«˜è¡€å‹ (ä¸­åº¦)")
            recommendations.append("å»ºè®®ç›‘æµ‹è¡€å‹ï¼Œå‡å°‘ç›åˆ†æ‘„å…¥ï¼Œä¿æŒå¥åº·é¥®é£Ÿï¼Œå¹¶å’¨è¯¢åŒ»ç”Ÿã€‚")
        elif lab_params.get("æ”¶ç¼©å‹ (mmHg)", 0) > 140 or lab_params.get("èˆ’å¼ å‹ (mmHg)", 0) > 90:
            diseases.append("é«˜è¡€å‹ (è½»åº¦)")
            recommendations.append("å»ºè®®å®šæœŸç›‘æµ‹è¡€å‹ï¼Œä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼ã€‚")

        # Coronary Artery Disease (CAD)
        if history.get("æ˜¯å¦æœ‰å¿ƒè„ç—…å®¶æ—å²ï¼Ÿ", "å¦") == "æ˜¯" or lab_params.get("ä½å¯†åº¦è„‚è›‹ç™½ (LDL-C, mg/dL)", 0) > 130:
            diseases.append("å† å¿ƒç—…")
            recommendations.append("å»ºè®®è¿›è¡Œå¿ƒè„å¥åº·æ£€æŸ¥ï¼Œé¿å…é«˜è„‚é¥®é£Ÿï¼Œå¹¶ä¿æŒé€‚åº¦è¿åŠ¨ã€‚")

        # Myocardial Infarction (MI)
        if symptoms.get("èƒ¸ç—›æ˜¯å¦åœ¨åŠ³ç´¯æ—¶åŠ é‡ï¼Ÿ", "å¦") == "æ˜¯" and lab_params.get("è‚Œé’™è›‹ç™½ (Troponin I/T, ng/mL)", 0) > 0.04:
            diseases.append("å¿ƒè‚Œæ¢—å¡")
            recommendations.append("è¿™æ˜¯ç´§æ€¥æƒ…å†µï¼Œè¯·ç«‹å³å°±åŒ»ã€‚")

        # Hyperlipidemia
        if lab_params.get("æ€»èƒ†å›ºé†‡ (Total Cholesterol, mg/dL)", 0) > 200 or lab_params.get("ä½å¯†åº¦è„‚è›‹ç™½ (LDL-C, mg/dL)", 0) > 130:
            diseases.append("é«˜è„‚è¡€ç—‡")
            recommendations.append("å»ºè®®å‡å°‘é«˜è„‚é¥®é£Ÿï¼Œå¢åŠ å¯Œå«çº¤ç»´çš„é£Ÿç‰©ï¼Œå¹¶å’¨è¯¢åŒ»ç”Ÿã€‚")

        # Heart Failure
        if symptoms.get("æ˜¯å¦å‘¼å¸å›°éš¾ï¼Ÿ", "å¦") == "æ˜¯" and lab_params.get("è‚Œé’™è›‹ç™½ (Troponin I/T, ng/mL)", 0) > 0.1:
            diseases.append("å¿ƒåŠ›è¡°ç«­")
            recommendations.append("è¿™æ˜¯ç´§æ€¥æƒ…å†µï¼Œè¯·ç«‹å³å°±åŒ»ã€‚")

        if not diseases:
            diseases.append("æ— æ˜æ˜¾å¿ƒè¡€ç®¡ç–¾ç—…é£é™©")
            recommendations.append("ä¿æŒå¥åº·çš„ç”Ÿæ´»æ–¹å¼ï¼Œå®šæœŸè¿›è¡Œå¥åº·æ£€æŸ¥ã€‚")

    return diseases, recommendations

MODEL_EXPLANATIONS = {
    "BioBERT": {
        "ä¸­æ–‡": "BioBERT æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹ç”Ÿç‰©åŒ»å­¦æ–‡æœ¬è®­ç»ƒçš„æ¨¡å‹ï¼Œé€‚ç”¨äºåˆ†æåŒ»å­¦ç›¸å…³çš„æ–‡æœ¬ã€‚",
        "English": "BioBERT is a model pre-trained on biomedical text, suitable for analyzing medical-related content."
    },
    "PubMedBERT": {
        "ä¸­æ–‡": "PubMedBERT æ˜¯åŸºäº PubMed æ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼Œä¸“æ³¨äºç”Ÿç‰©åŒ»å­¦æ–‡çŒ®çš„ç†è§£ã€‚",
        "English": "PubMedBERT is trained on PubMed data and focuses on understanding biomedical literature."
    },
    "ClinicalBERT": {
        "ä¸­æ–‡": "ClinicalBERT æ˜¯é’ˆå¯¹ä¸´åºŠæ–‡æœ¬ï¼ˆå¦‚ç”µå­ç—…å†ï¼‰ä¼˜åŒ–çš„æ¨¡å‹ï¼Œé€‚åˆåˆ†ææ‚£è€…ç›¸å…³çš„ä¸´åºŠæ•°æ®ã€‚",
        "English": "ClinicalBERT is optimized for clinical text (such as electronic medical records) and is suitable for analyzing patient-related clinical data."
    }
}


def aggregate_model_predictions(results, lang="ä¸­æ–‡"):
    """
    Aggregates probabilities from all models to determine the overall risk level,
    and outputs labels in the specified language.
    """
    # Define risk labels based on language
    if lang == "English":
        risk_labels = ["Low Risk", "Moderate Risk", "High Risk"]
    else:
        risk_labels = ["ä½é£é™©", "ä¸­é£é™©", "é«˜é£é™©"]

    # Initialize aggregated probabilities
    aggregated_probabilities = {label: 0 for label in risk_labels}
    model_count = 0

    for model_result in results:
        if isinstance(model_result, dict) and "probabilities" in model_result:
            for risk, score in model_result["probabilities"].items():
                # Only aggregate if the risk label matches the current language
                if risk in aggregated_probabilities:
                    aggregated_probabilities[risk] += score
            model_count += 1

    # Avoid division by zero
    if model_count == 0:
        return None, aggregated_probabilities

    # Average the probabilities
    for risk in aggregated_probabilities:
        aggregated_probabilities[risk] /= model_count

    # Determine the most likely risk level
    most_likely = max(aggregated_probabilities, key=aggregated_probabilities.get)
    return most_likely, aggregated_probabilities


def analyze_structured_inputs(symptoms, history, lab_params, file_output, lang):

    # Replace None values in symptoms with "å¦"/"No"
    if lang == "ä¸­æ–‡":
        symptoms = {key: (value if value is not None else "å¦")
                    for key, value in symptoms.items()}
        section_user = "### ğŸ“ ç”¨æˆ·è¾“å…¥"
        section_symptoms = "#### ğŸ©º ç—‡çŠ¶"
        section_history = "#### ğŸ¥ ç—…å²"
        section_lab = "#### ğŸ§ª å®éªŒå®¤å‚æ•°"
        section_disease = "### ğŸ©º ç–¾ç—…åˆ†ç±»"
        section_recommend = "### ğŸ’¡ å»ºè®®"
        section_model = "### æ¨¡å‹é¢„æµ‹"
        section_agg = "### ç»¼åˆåˆ†æ"
        bullet = "ğŸ”¹"
        risk_label = "é£é™©ç­‰çº§"
        prob_label = "æ¦‚ç‡åˆ†å¸ƒ"
        explain_label = "æ¨¡å‹è§£é‡Š"
        agg_risk = "ç»¼åˆé£é™©ç­‰çº§"
        agg_prob = "ç»¼åˆæ¦‚ç‡åˆ†å¸ƒ"
        agg_explain = "æ¨¡å‹é¢„æµ‹å¯èƒ½å­˜åœ¨å·®å¼‚ï¼Œå› ä¸ºå®ƒä»¬åŸºäºä¸åŒçš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚å»ºè®®æ ¹æ®ç»¼åˆåˆ†æç»“æœé‡‡å–è¡ŒåŠ¨ï¼Œå¹¶åœ¨å¿…è¦æ—¶å’¨è¯¢åŒ»ç”Ÿã€‚"
        history = {k: (v if v is not None else "å¦")
                   for k, v in history.items()}
    else:
        symptoms = {key: (value if value is not None else "No")
                    for key, value in symptoms.items()}
        section_user = "### ğŸ“ User Inputs"
        section_symptoms = "#### ğŸ©º Symptoms"
        section_history = "#### ğŸ¥ Medical History"
        section_lab = "#### ğŸ§ª Lab Parameters"
        section_disease = "### ğŸ©º Disease Classification"
        section_recommend = "### ğŸ’¡ Recommendations"
        section_model = "### Model Predictions"
        section_agg = "### Aggregated Analysis"
        bullet = "ğŸ”¹"
        risk_label = "Risk Level"
        prob_label = "Probability Distribution"
        explain_label = "Model Explanation"
        agg_risk = "Overall Risk Level"
        agg_prob = "Aggregated Probability Distribution"
        agg_explain = "Model predictions may differ because they are trained on different datasets. Please act according to the combined analysis and consult a doctor if necessary."

    print(f"Processing symptoms: {symptoms}")
    print(f"Processing history: {history}")
    print(f"Processing lab parameters: {lab_params}")
    # Combine structured inputs into a single text representation
    structured_text = (
        f"{section_user}:\n\n"
        f"{section_symptoms}:\n" +
        "\n".join([f"{bullet} {q}: {a}" for q, a in symptoms.items()]) +
        f"\n\n{section_history}:\n" +
        "\n".join([f"{bullet} {q}: {a}" for q, a in history.items()]) +
        f"\n\n{section_lab}:\n" +
        "\n".join([f"{bullet} {q}: {a}" for q, a in lab_params.items()])
    )

    # Process file if provided
    if file_output:
        file_data = process_file(file_output, lang)
        if isinstance(file_data, str):
            try:
                file_data = json.loads(file_data)
            except json.JSONDecodeError:
                return f"Error processing file: {file_data}"
    if file_data:
        if lang == "ä¸­æ–‡":
            file_section = "### ä¸Šä¼ æ–‡ä»¶å†…å®¹è§£æ"
        else:
            file_section = "### File Content Analysis"
        file_mapping = map_uploaded_file(file_data)
        print(f"File mapping: {file_mapping}")

    print(f"Processing symptoms: {symptoms}")
    print(f"Processing history: {history}")
    print(f"Processing lab parameters: {lab_params}")

    # TODO: If file_mapping exist, compare file_mapping with lab_params and use lab_params if overlapping values exist

    # Combine structured inputs into a single text representation
    structured_text = (
        f"{section_user}:\n\n"
        f"{section_symptoms}:\n" +
        "\n".join([f"{bullet} {q}: {a}" for q, a in symptoms.items()]) +
        f"\n\n{section_history}:\n" +
        "\n".join([f"{bullet} {q}: {a}" for q, a in history.items()]) +
        f"\n\n{section_lab}:\n" +
        "\n".join([f"{bullet} {q}: {a}" for q, a in lab_params.items()])
    )

    if file_mapping:
        structured_text += f"\n{file_section}:\n{dict(file_mapping)}" 

    print(f"Structured text for analysis: {structured_text}")
    # Classify cardiovascular diseases and get recommendations
    diseases, recommendations = classify_cardiovascular_disease(
        symptoms, history, lab_params, lang)

    # Get predictions from all models
    model_results = []
    for model_name, classifier in pipelines.items():
        try:
            predictions = classifier(structured_text)
            print(predictions)
            probabilities = {
                LABEL_MAPPING[pred["label"]][lang]: pred["score"] for pred in predictions}
            most_likely = max(probabilities, key=probabilities.get)
            explanation = MODEL_EXPLANATIONS[model_name][lang]
            model_results.append({
                "model_name": model_name,
                "most_likely": most_likely,
                "probabilities": probabilities,
                "explanation": explanation
            })
        except Exception as e:
            model_results.append({
                "model_name": model_name,
                "error": str(e)
            })

    # Aggregate predictions
    aggregated_risk, aggregated_probabilities = aggregate_model_predictions(
        model_results, lang)

    # Format the results for display
    formatted_results = [structured_text]
    formatted_results.append(
        f"{section_disease}:\n" +
        "\n".join([f"{bullet} {disease}" for disease in diseases])
    )
    formatted_results.append(
        f"{section_recommend}:\n" +
        "\n".join(
            [f"{bullet} {recommendation}" for recommendation in recommendations])
    )

    # Add model-specific results
    formatted_results.append(f"{section_model}:")
    for result in model_results:
        if "error" in result:
            formatted_results.append(f"- **{result['model_name']}**: Error: {result['error']}")
        else:
            formatted_results.append(
                f"- **{result['model_name']}**:\n"
                f"  **{risk_label}:** {result['most_likely']}\n"
                f"  **{prob_label}:**\n" +
                "\n".join([f"    {bullet} {risk}: {score:.2f}" for risk, score in result["probabilities"].items()]) +
                f"\n  **{explain_label}:** {result['explanation']}\n"
            )

    # Add aggregated analysis
    formatted_results.append(
        f"{section_agg}:\n"
        f"- **{agg_risk}:** {aggregated_risk}\n"
        f"- **{agg_prob}:**\n" +
        "\n".join([f"  {bullet} {risk}: {score:.2f}" for risk, score in aggregated_probabilities.items()]) +
        f"\n- **{('è¯´æ˜' if lang == 'ä¸­æ–‡' else 'Explanation')}:** {agg_explain}"
    )

    print("model_results:", model_results)
    openai_result = summarize_model_outputs(model_results, lang, mock=True)
    print("OpenAI result:", openai_result)
    if openai_result:
        formatted_results.append(openai_result)

    return "\n\n".join(formatted_results)

# Create Gradio interface for each language
def summarize_model_outputs(model_outputs, language="ä¸­æ–‡", mock= False):
    """
    Summarizes model outputs and returns a formatted string.
    Args:
        model_outputs: list of dicts with model results

    """
    mock_chinese_text = """
1. æ ¹æ®ä¸‰ä¸ªæ¨¡å‹çš„è¾“å‡ºï¼ŒBioBERTã€PubMedBERTå’ŒClinicalBERTéƒ½å°†è¯¥æ–‡æœ¬åˆ¤æ–­ä¸ºé«˜é£é™©ï¼Œæ¦‚ç‡åˆ†åˆ«ä¸º0.39ã€0.48å’Œ0.45ã€‚

2. ä¸‰ä¸ªæ¨¡å‹ä¹‹é—´çš„ä¸€è‡´æ€§è¾ƒé«˜ï¼Œéƒ½å°†æ–‡æœ¬åˆ¤æ–­ä¸ºé«˜é£é™©ã€‚è™½ç„¶åœ¨é£é™©æ¦‚ç‡ä¸Šæœ‰äº›è®¸å·®å¼‚ï¼Œä½†å·®è·å¹¶ä¸å¤§ã€‚

3. ç»¼åˆä¸‰ä¸ªæ¨¡å‹çš„åˆ¤æ–­ï¼Œç³»ç»Ÿåº”è¯¥å°†è¯¥æ–‡æœ¬åˆ†ç±»ä¸ºâ€œé«˜é£é™©â€ã€‚

4. å»ºè®®ç”¨æˆ·è¡ŒåŠ¨ï¼šé‰´äºä¸‰ä¸ªæ¨¡å‹éƒ½å°†æ–‡æœ¬åˆ¤æ–­ä¸ºé«˜é£é™©ï¼Œå»ºè®®ç”¨æˆ·å°½å¿«å°±åŒ»ï¼Œå¹¶å‘åŒ»ç”Ÿè¯¦ç»†æè¿°ç›¸å…³ç—‡çŠ¶å’Œç—…æƒ…ã€‚å¦‚æœå¯èƒ½ï¼Œå‡†å¤‡ç›¸å…³çš„åŒ»ç–—è®°å½•å’Œæ£€æŸ¥ç»“æœï¼Œä»¥ä¾¿åŒ»ç”Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°é£é™©ã€‚

[English Translation]

1. According to the outputs of the three models, BioBERT, PubMedBERT, and ClinicalBERT all classify the text as high risk, with probabilities of 0.39, 0.48, and 0.45 respectively.

2. There is a high level of consistency between the three models, all classifying the text as high risk. Although there are slight differences in risk probabilities, the gap is not large.

3. Combining the judgments of the three models, the system should classify this text as "high risk".

4. Suggested User Action: Given that all three models classify the text as high risk, it is recommended that the user seek medical attention as soon as possible and provide the doctor with a detailed description of the symptoms and condition. If possible, prepare relevant medical records and test results to help the doctor more accurately assess the risk.
    """
    mock_english_text = """
    1. According to the outputs of the three models, BioBERT, PubMedBERT, and ClinicalBERT all classify the text as high risk, with probabilities of 0.39, 0.48, and 0.45 respectively.

2. There is a high level of consistency between the three models, all classifying the text as high risk. Although there are slight differences in risk probabilities, the gap is not large.

3. Combining the judgments of the three models, the system should classify this text as "high risk".

4. Suggested User Action: Given that all three models classify the text as high risk, it is recommended that the user seek medical attention as soon as possible and provide the doctor with a detailed description of the symptoms and condition. If possible, prepare relevant medical records and test results to help the doctor more accurately assess the risk.
    """

    if mock:
        if language == "ä¸­æ–‡":
            return mock_chinese_text
        else:
            return mock_english_text
    else:
        return summarize_model_outputs_llm(model_outputs, language)
    

def make_tab(lang):
    """
    Creates a tab for the specified language (Chinese or English).
    """
    L = {
        "yes": "æ˜¯" if lang == "ä¸­æ–‡" else "Yes",
        "no": "å¦" if lang == "ä¸­æ–‡" else "No",
        "nums": [
            ("æ”¶ç¼©å‹ (mmHg)" if lang == "ä¸­æ–‡" else "Systolic BP (mmHg)", 60, 220, 120),
            ("èˆ’å¼ å‹ (mmHg)" if lang == "ä¸­æ–‡" else "Diastolic BP (mmHg)", 40, 120, 80),
            ("ä½å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡ (mg/dL)" if lang ==
             "ä¸­æ–‡" else "LDL Cholesterol (mg/dL)", 50, 200, 100),
            ("é«˜å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡ (mg/dL)" if lang ==
             "ä¸­æ–‡" else "HDL Cholesterol (mg/dL)", 20, 100, 50),
            ("æ€»èƒ†å›ºé…¯ (mg/dL)" if lang ==
             "ä¸­æ–‡" else "Total Cholesterol (mg/dL)", 0, 300, 200),
            ("è‚Œé’™è›‹ç™½ (Troponin I/T, ng/mL)" if lang ==
             "ä¸­æ–‡" else "Troponin I/T (ng/mL)", 0, 50, 0.01)
        ]
    }
    yesno = [L["yes"], L["no"]]

    # Grouped questions
    symptom_questions = [
        "èƒ¸ç—›æ˜¯å¦åœ¨åŠ³ç´¯æ—¶åŠ é‡ï¼Ÿ" if lang == "ä¸­æ–‡" else "Is chest pain aggravated by exertion?",
        "æ˜¯å¦ä¸ºå‹è¿«æ„Ÿæˆ–ç´§ç¼©æ„Ÿï¼Ÿ" if lang == "ä¸­æ–‡" else "Is it a pressing or tightening sensation?",
        "æ˜¯å¦æŒç»­è¶…è¿‡5åˆ†é’Ÿï¼Ÿ" if lang == "ä¸­æ–‡" else "Does it last more than 5 minutes?",
        "æ˜¯å¦æ”¾å°„è‡³è‚©/èƒŒ/ä¸‹å·´ï¼Ÿ" if lang == "ä¸­æ–‡" else "Does it radiate to shoulder/back/jaw?",
        "æ˜¯å¦åœ¨ä¼‘æ¯åç¼“è§£ï¼Ÿ" if lang == "ä¸­æ–‡" else "Is it relieved by rest?",
        "æ˜¯å¦ä¼´å†·æ±—ï¼Ÿ" if lang == "ä¸­æ–‡" else "Is it accompanied by cold sweat?",
        "æ˜¯å¦å‘¼å¸å›°éš¾ï¼Ÿ" if lang == "ä¸­æ–‡" else "Is there shortness of breath?",
        "æ˜¯å¦æ¶å¿ƒæˆ–å‘•åï¼Ÿ" if lang == "ä¸­æ–‡" else "Is there nausea or vomiting?",
        "æ˜¯å¦å¤´æ™•æˆ–æ™•å¥ï¼Ÿ" if lang == "ä¸­æ–‡" else "Is there dizziness or fainting?",
        "æ˜¯å¦å¿ƒæ‚¸ï¼Ÿ" if lang == "ä¸­æ–‡" else "Is there palpitations?"
    ]
    history_questions = [
        "æ˜¯å¦æ‚£æœ‰é«˜è¡€å‹ï¼Ÿ" if lang == "ä¸­æ–‡" else "Do you have hypertension?",
        "æ˜¯å¦æ‚£ç³–å°¿ç—…ï¼Ÿ" if lang == "ä¸­æ–‡" else "Do you have diabetes?",
        "æ˜¯å¦æœ‰é«˜è¡€è„‚ï¼Ÿ" if lang == "ä¸­æ–‡" else "Do you have hyperlipidemia?",
        "æ˜¯å¦å¸çƒŸï¼Ÿ" if lang == "ä¸­æ–‡" else "Do you smoke?",
        "æ˜¯å¦æœ‰å¿ƒè„ç—…å®¶æ—å²ï¼Ÿ" if lang == "ä¸­æ–‡" else "Family history of heart disease?",
        "è¿‘æœŸæ˜¯å¦æœ‰æƒ…ç»ªå‹åŠ›ï¼Ÿ" if lang == "ä¸­æ–‡" else "Recent emotional stress?"
    ]

    # Create Gradio components

    with gr.Group():
        gr.Markdown("### ğŸ©º ç—‡çŠ¶ / Symptoms" if lang == "ä¸­æ–‡" else "### ğŸ©º Symptoms")
        symptom_fields = [gr.Radio(choices=yesno, label=q, value=None)
                          for q in symptom_questions]

    with gr.Group():
        gr.Markdown("### ğŸ¥ ç—…å² / Medical History" if lang == "ä¸­æ–‡" else "### ğŸ¥ Medical History")
        history_fields = [gr.Radio(choices=yesno, label=q, value=None)
                          for q in history_questions]

    with gr.Group():
        gr.Markdown("### ğŸ§ª å®éªŒå®¤å‚æ•° / Lab Parameters" if lang == "ä¸­æ–‡" else "### ğŸ§ª Lab Parameters")
        lab_fields = [
            gr.Number(label=q, minimum=minv, maximum=maxv, value=val)
            for q, minv, maxv, val in L["nums"]
        ]


    with gr.Group():
        label = "ä¸Šä¼ æ–‡ä»¶" if lang == "ä¸­æ–‡" else "Upload File"
        gr.Markdown(label)
        file_input = gr.File(label=label, file_types=[
                             ".txt", ".pdf", ".docx"], elem_id="file_upload")

    # Combine all fields
    fields = symptom_fields + history_fields + lab_fields + [file_input]

    # Output and submit button
    output_text = gr.Textbox(label="ç»“æœ / Results" if lang == "ä¸­æ–‡" else "Results")
    reset_button = gr.Button("é‡ç½®" if lang == "ä¸­æ–‡" else "Reset")
    submit_button = gr.Button("æäº¤ / Submit" if lang == "ä¸­æ–‡" else "Submit")

    # Submit button functionality
    submit_button.click(
        fn=lambda *inputs: analyze_structured_inputs(
            symptoms={q: inputs[i] for i, q in enumerate(symptom_questions)},
            history={q: inputs[i + len(symptom_questions)] for i, q in enumerate(history_questions)},
            lab_params={
                lab_fields[i].label: inputs[i +
                                            len(symptom_questions) + len(history_questions)]
                for i in range(len(lab_fields))
                if inputs[i + len(symptom_questions) + len(history_questions)] not in (None, 0)
            },
            file_output=inputs[-1],
            lang=lang
        ),
        inputs=fields,
        outputs=[output_text]
    )

    reset_button.click(
        fn=lambda: [None] * len(fields),  # æ¸…ç©ºæ‰€æœ‰è¾“å…¥
        inputs=None,
        outputs=fields
    )

    # Create Gradio interface
    return gr.Column(fields + [submit_button, output_text, reset_button, gr.Markdown("---")])

def process_file(file, lang="English", mock=True):
    """
    Process the uploaded docx file and use OpenAI API to extract key-value pairs.
    If mock is True, return a fixed JSON structure for testing.
    """
    # TODO: Implement English mock data and return based on Lang
    if mock:
        if lang == "ä¸­æ–‡":
            mock_data = {
                "ç™ŒèƒšæŠ—åŸ (CEA)": "3.22 ng/ml (â‰¤5)",
                "ç”²èƒè›‹ç™½": "3.52 ng/ml (â‰¤7)",
                "é«˜å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡": "78.15 mg/dL (>40)",
                "ä½å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡": "171.4 mg/dL (<130) â†‘",
                "ç”˜æ²¹ä¸‰é…¯": "110.7 mg/dL (<150)",
                "æ€»èƒ†å›ºé†‡": "266.5 mg/dL (<200) â†‘",
                "å°¿ç´ ": "37.64 mg/dL (18.63â€“52.85)",
                "æ€»äºŒæ°§åŒ–ç¢³": "26.8 mEq/L (22.0â€“29.0)",
                "å°¿é…¸": "3.97 mg/dL (2.61â€“6.00)",
                "è‚Œé…": "0.71 mg/dL (0.46â€“0.92)"
            }
        else:
            mock_data = {
                "LDL Cholesterol": "84 mg/dL (Ref: < 135 mg/dL)",
                "Total Cholesterol": "185 mg/dL (Ref: < 200 mg/dL)",
                "HDL Cholesterol": "76 mg/dL (Ref: â‰¥ 40 mg/dL)",
                "Non-HDL Cholesterol": "109 mg/dL (Ref: < 162 mg/dL)",
                "Triglycerides": "144 mg/dL (Ref: < 150 mg/dL)",
                "A1c": "5.4% (Ref: < 6.0%)",
                "eGFR": "72 mL/min/1.73mÂ² (Ref: â‰¥ 60)",
                "Urea (BUN equivalent)": "23 mg/dL (Ref: ~7 â€“ 23 mg/dL)",
                "Iron": "67 Âµg/dL (Ref: 40 â€“ 160 Âµg/dL)",
                "Vitamin B12": "149 pg/mL (Ref: 148â€“220: Insufficiency)",
                "PSA (Prostate Specific Antigen)": "1.68 ng/mL (Ref: < 3.5 ng/mL)",
                "DHEAS": "148 Âµg/dL (Ref: ~69 â€“ 305 Âµg/dL)",
                "WBC Count": "4.1 x10â¹/L (Ref: 4.5 â€“ 11.0 x10â¹/L)",
                "RBC Count": "4.9 x10Â¹Â²/L (Ref: 4.4 â€“ 5.9 x10Â¹Â²/L)",
                "Hemoglobin": "15.2 g/dL (Ref: 14.0 â€“ 18.0 g/dL)",
                "Lymphocytes": "0.8 x10â¹/L (Ref: 1.0 â€“ 3.3 x10â¹/L)",
                "Ferritin": "473 ng/mL (Ref: > 220 ng/mL)",
                "Platelets": "170 x10â¹/L (Ref: 140 â€“ 440 x10â¹/L)"
            }
        
        return json.dumps(mock_data, indent=2, ensure_ascii=False)
    if file is None:
        return "No file uploaded."
    try:
        # Save uploaded file to a temp path
        temp_path = file.name
        result = extract_key_value_pairs(temp_path)
        if result is None:
            return "Could not extract key-value pairs. See logs for details."
        # Pretty print JSON result
        return json.dumps(result, indent=2, ensure_ascii=False)
    except Exception as e:
        return f"Error processing file: {e}"


def map_uploaded_file(data):
    """
    Map the uploaded file to the appropriate key-value pairs.
    æ”¯æŒ value ä¸º "æ•°å€¼ å•ä½ (å‚è€ƒèŒƒå›´)" çš„å­—ç¬¦ä¸²æ ¼å¼ã€‚
    """
    if data is None:
        return "No content returned."
    result = {}
    for name, entry in data.items():
        # ç”¨æ­£åˆ™æå–æ•°å€¼å’Œå•ä½
        match = re.match(r"([-\d.]+)\s*([a-zA-ZÂµ/%]+)", entry)
        if match:
            value_str, unit = match.groups()
            try:
                value = float(value_str)
                result[f"{name} ({unit})"] = value
            except Exception:
                continue
    return result


# Launch Gradio app
if __name__ == "__main__":
    with gr.Blocks() as app:
        gr.Markdown("## ğŸŒ æ™ºèƒ½å¿ƒè¡€ç®¡è¯„ä¼°ç³»ç»Ÿ | Bilingual Cardiovascular Assistant")
        with gr.Tabs():
            with gr.TabItem("ä¸­æ–‡"):
                make_tab("ä¸­æ–‡")
            with gr.TabItem("English"):
                make_tab("English")
        app.launch(share=True)